{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f559a3-a4e7-4034-bb91-da01a068dc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6285d19-5508-4eb2-898e-27df94c066f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from libpysal.graph import read_parquet\n",
    "from core.generate_clusters import get_tree, get_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61abb365-8d9a-4069-8121-155b3fba3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_dir = \"/data/uscuni-ulce/processed_data/chars/\"\n",
    "graph_dir = \"/data/uscuni-ulce/processed_data/neigh_graphs/\"\n",
    "tessellations_dir = '/data/uscuni-ulce/processed_data/tessellations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a0839f-4650-4484-81dd-70df3e506b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id = 5883 # freiburtg\n",
    "# region_id = 69333 # prague\n",
    "# region_id = 139196 # prague\n",
    "\n",
    "region_id = 66593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef534d5a-a78a-4379-b779-236f23abaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(chars_dir + f'primary_chars_{region_id}.parquet')\n",
    "graph = read_parquet(graph_dir + f\"tessellation_graph_{region_id}.parquet\")\n",
    "tessellation = gpd.read_parquet(\n",
    "        tessellations_dir + f\"tessellation_{region_id}.parquet\"\n",
    ")\n",
    "\n",
    "building_graph = graph.subgraph(graph.unique_ids[graph.unique_ids >= 0])\n",
    "labels = building_graph.component_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4887a469-c102-4eb5-aa00-20150ade209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### clustering parameters\n",
    "min_cluster_size = 75\n",
    "\n",
    "# spatial_lag = 3\n",
    "# kernel='gaussian' \n",
    "# lag_type = '_median'\n",
    "\n",
    "lag_type = None\n",
    "spatial_lag = 0\n",
    "kernel='None'\n",
    "\n",
    "clip = None\n",
    "\n",
    "to_drop = ['stcSAl','stbOri','stcOri','stbCeA', \n",
    "           'ldkAre', 'ldkPer', 'lskCCo', 'lskERI',\n",
    "           'lskCWA', 'ltkOri', 'ltkWNB', 'likWBB', 'likWCe',\n",
    "          'licBAD',\n",
    "          'misBAD',\n",
    "\n",
    "           'ssbCCM',\n",
    "           'ssbCCD'\n",
    "           \n",
    "          ]\n",
    "\n",
    "\n",
    "linkage='ward'\n",
    "metric='euclidean'\n",
    "eom_clusters = False\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer\n",
    "scalar = QuantileTransformer(subsample=None, output_distribution='uniform')\n",
    "# scalar = QuantileTransformer(subsample=None, output_distribution='normal')\n",
    "# scalar = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa582b9-ea7a-4724-bdb1-01aa88f6658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_clustering_data(X_train, scalar, clip, to_drop):\n",
    "    '''Data pre-processing before clustering is carried out.'''\n",
    "    ## drop non-buildings\n",
    "    X_train = X_train[X_train.index >= 0]\n",
    "\n",
    "    # drop 'to_drop' columns and spatial lag\n",
    "    all_drop = []\n",
    "    for c in to_drop:\n",
    "        all_drop += X_train.columns[X_train.columns.str.contains(c)].tolist()\n",
    "    X_train = X_train.drop(all_drop, axis=1)\n",
    "\n",
    "    # standardise data\n",
    "    vals = scalar.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(vals, columns=X_train.columns, index=X_train.index)\n",
    "    vals = np.nan_to_num(X_train)\n",
    "    X_train = pd.DataFrame(vals, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "    # drop any columns with no variation\n",
    "    stats = X_train.describe()\n",
    "    X_train = X_train.drop(stats.columns[stats.loc['std'] == 0], axis=1)\n",
    "\n",
    "    #optionally clip the data\n",
    "    if clip is not None:\n",
    "        X_train = X_train.clip(*clip)\n",
    "\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040bfcda-32a7-4d13-834a-c85e424e01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_data(X_train, graph, scalar, to_drop, clip, \n",
    "                 min_cluster_size, linkage, metric, eom_clusters=True):\n",
    "    '''Split the input data into connected components and carry out an agglomerative clustering for each component independently.\n",
    "    Pre-process the input data, cluster and then carry out post-processing and finally combine all the seperate clusterings into one set of clusters.'''\n",
    "    \n",
    "    # label building input data, could work with empty tess as well\n",
    "    building_graph = graph.subgraph(graph.unique_ids[graph.unique_ids >= 0])\n",
    "    labels = building_graph.component_labels\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for label, group in labels.groupby(labels):\n",
    "    \n",
    "        if group.shape[0] <= min_cluster_size:\n",
    "            component_clusters = np.full(group.shape[0], -1)\n",
    "    \n",
    "        else:\n",
    "            component_buildings_data = preprocess_clustering_data(X_train.loc[group.index.values], \n",
    "                                                                  scalar=scalar, clip=clip, to_drop=to_drop)\n",
    "            component_graph = building_graph.subgraph(group.index.values)\n",
    "            ward_tree = get_tree(component_buildings_data, component_graph.transform('B').sparse, linkage, metric)\n",
    "    \n",
    "            # # sometimes ward linkage breaks the monotonic increase in the MST\n",
    "            # # if that happens shift all distances by the max drop\n",
    "            # # need a loop because several connections might be problematic\n",
    "            problem_idxs = np.where(ward_tree[1:, 2] < ward_tree[0:-1, 2])[0]\n",
    "            while problem_idxs.shape[0]:\n",
    "                ward_tree[problem_idxs + 1, 2] = ward_tree[problem_idxs, 2] + .01\n",
    "                problem_idxs = np.where(ward_tree[1:, 2] < ward_tree[0:-1, 2])[0]\n",
    "            # check if ward tree distances are always increasing\n",
    "            assert (ward_tree[1:, 2] >= ward_tree[0:-1, 2]).all()\n",
    "            \n",
    "            component_clusters = get_clusters(ward_tree, min_cluster_size, \n",
    "                                              component_buildings_data.shape[0], \n",
    "                                              eom_clusters=eom_clusters)\n",
    "                \n",
    "           # ## post process - needs changing, since it doesnt make much of a difference\n",
    "           #  res = component_buildings_data.groupby(component_clusters).apply(post_process_clusters_tightening, min_cluster_size=min_cluster_size, t=15)\n",
    "           #  if res.shape[0] == 1:\n",
    "           #      component_clusters = pd.Series(res.values[0], res.columns)\n",
    "           #  else:\n",
    "           #      component_clusters = pd.Series(res.values, res.index.get_level_values(1)).loc[component_buildings_data.index].values\n",
    "            \n",
    "            # for c in np.unique(component_clusters):\n",
    "            #     # if c == -1: continue\n",
    "            #     cluster_graph = component_graph.subgraph(group.index[component_clusters == c].values)\n",
    "            #     assert cluster_graph.n_components == 1\n",
    "        \n",
    "        results[label] = component_clusters\n",
    "\n",
    "    ### relabel local clusters(0,1,2,0,1) to regional clusters(0_0,0_1,0_2, 0_0,0_1,) etc\n",
    "    label_groups = labels.groupby(labels)\n",
    "    region_cluster_labels = []\n",
    "    for label, component_clusters in results.items():\n",
    "        group = label_groups.get_group(label)\n",
    "        component_labels = str(label) + '_' + pd.Series(component_clusters.astype(str), \n",
    "                                                        index=group.index.values)\n",
    "        region_cluster_labels.append(component_labels)\n",
    "    \n",
    "    region_cluster_labels = pd.concat(region_cluster_labels).sort_index()\n",
    "    assert (X_train[X_train.index >= 0].index == region_cluster_labels.index).all()\n",
    "    \n",
    "    return region_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d5bd8-bd3b-415a-8fb2-1d8cced16e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a411f0-d4dc-4081-bfa1-e250977f5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_data = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fce0f-f7b7-427c-b058-4e3ce89fe910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28f61ee-daed-4562-a4e4-045fe4e2e3f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (898). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (511). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (95). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (83). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (213). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (173). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (285). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (172). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (86). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (98). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (339). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (111). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (132). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (82). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (87). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (126). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (376). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (163). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (83). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "region_cluster_labels = cluster_data(clustering_data, graph, scalar, \n",
    "                                     to_drop, clip, min_cluster_size, \n",
    "                                     linkage, metric, eom_clusters=eom_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd887b-c25c-4acb-b076-b7fc032e4c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46d937-9d9a-4893-b03c-4608305e0a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d9cd9-8e29-4bb9-aded-25a3974e8edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f2eaab-aced-4db0-90c2-ce21aa3298a4",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2545d7-259e-41cc-aabc-7f9622db7f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0fe9604-4f63-434b-abf0-fef48337f060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "plotting = tessellation[tessellation.index >=0]\n",
    "plotting['regional_label'] = region_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10a8cb0-5ef2-4301-b59c-85831042b47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "vals, indx = plotting['regional_label'].factorize()\n",
    "vals[np.isin(vals, np.where(indx.str.split('_').str[-1] == '-1')[0])] = -1\n",
    "plotting['regional_label_factor'] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c099a1-44d5-4c31-90bb-f0f213a60552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from core.cluster_validation import get_color\n",
    "final_colors = pd.DataFrame(get_color(vals), vals).drop_duplicates()\n",
    "final_colors.loc[-1] = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a188d9-4c56-41e4-adb3-54489a55a7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasen/urban_taxonomy/.pixi/envs/default/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "plotting['geometry'] = plotting.simplify(1).to_crs(epsg=4326).make_valid()\n",
    "plotting = plotting[plotting['geometry'].geom_type == 'Polygon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fce07e2-855d-4d47-917e-d36160788ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.9 ms, sys: 11 ms, total: 88.9 ms\n",
      "Wall time: 88.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lonboard\n",
    "# plotting = tessellation[tessellation.index.isin(X_train.index)].copy()\n",
    "layer = lonboard.SolidPolygonLayer.from_geopandas(plotting, opacity=.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ccb73e-be06-46d5-b457-f12596daea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sidecar import Sidecar\n",
    "sc = Sidecar(title=f'Final Clusters')\n",
    "m = lonboard.Map(layer)\n",
    "with sc:\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9752ede0-a806-4bc7-965e-eb1ec6e7738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.cluster_validation import get_color\n",
    "layer.get_fill_color = final_colors.loc[plotting.regional_label_factor].values.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e169ed-2715-4d14-a283-86ab3d81deae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f8b4a-e49c-44c7-8629-a822579b855c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8813e-182c-4401-884a-fcd237262d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7581768d-8711-49bb-8ec6-0990bf2f6f92",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3debfe17-ba82-427c-a0e1-25e43169cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "morphotopes_dir = '/data/uscuni-ulce/processed_data/morphotopes/'\n",
    "from core.generate_clusters import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68e23fa-026e-4d35-ab2a-f2db2996eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Generating morphotopes data----------\n"
     ]
    }
   ],
   "source": [
    "region_cluster_labels.to_frame('morphotope_label').to_parquet(morphotopes_dir + f'tessellation_labels_morphotopes_{region_id}_{min_cluster_size}_{spatial_lag}_{lag_type}_{kernel}_{eom_clusters}.pq')\n",
    "\n",
    "# generate morphotopes data\n",
    "print(\"--------Generating morphotopes data----------\")\n",
    "component_data = X_train.loc[region_cluster_labels.index]\n",
    "component_data = component_data.groupby(region_cluster_labels.values).agg([percentile(25), \n",
    "                                                         'median', \n",
    "                                                         percentile(75), 'std', 'mean'] )\n",
    "# save sizes for clustering\n",
    "component_data[('Size', 'Size')] = X_train.loc[region_cluster_labels.index].groupby(region_cluster_labels.values).size()\n",
    "\n",
    "# store morphotopes data\n",
    "component_data.to_parquet(morphotopes_dir + f'data_morphotopes_{region_id}_{min_cluster_size}_{spatial_lag}_{lag_type}_{kernel}_{eom_clusters}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5663a7b-0694-4cef-8270-49957967317e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7be2f60c-ff9e-4add-95d1-87dd85d4b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_datadir = \"/data/uscuni-ulce/\"\n",
    "region_hulls = gpd.read_parquet(\n",
    "        regions_datadir + \"regions/\" + \"cadastre_regions_hull.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc6e12d7-7d40-416b-accb-a8cdcbf47832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_hulls.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4f2add3a-9f43-4a5b-89ea-320c47025da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 66593 - nad ustie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08444f8c-d33d-4bd0-89c4-c84a2d32a9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
